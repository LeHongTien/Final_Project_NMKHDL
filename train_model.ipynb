{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cài đặt các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Đọc dữ liệu từ file \"cleaned_arxiv_cs_papers_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314049, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'cleaned_arxiv_cs_papers_all.csv'\n",
    "raw_df = pd.read_csv(file_name)\n",
    "raw_df.head()\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>updated</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>comment</th>\n",
       "      <th>topic_count</th>\n",
       "      <th>published_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2412.10373v1</td>\n",
       "      <td>Sicheng Zuo,Wenzhao Zheng,Yuanhui Huang,Jie Zh...</td>\n",
       "      <td>2024-12-13 18:59:54</td>\n",
       "      <td>2024-12-13 18:59:54</td>\n",
       "      <td>GaussianWorld: Gaussian World Model for Stream...</td>\n",
       "      <td>3D occupancy prediction is important for aut...</td>\n",
       "      <td>cs.CV, cs.AI, cs.LG</td>\n",
       "      <td>Code is available at: https://github.com/zuosc...</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2412.10371v1</td>\n",
       "      <td>Wenzhao Zheng,Junjie Wu,Yao Zheng,Sicheng Zuo,...</td>\n",
       "      <td>2024-12-13 18:59:30</td>\n",
       "      <td>2024-12-13 18:59:30</td>\n",
       "      <td>GaussianAD: Gaussian-Centric End-to-End Autono...</td>\n",
       "      <td>Vision-based autonomous driving shows great ...</td>\n",
       "      <td>cs.CV, cs.AI, cs.LG, cs.RO</td>\n",
       "      <td>Code is available at: https://github.com/wzzhe...</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2402.01886v2</td>\n",
       "      <td>Mark Beliaev,Ramtin Pedarsani</td>\n",
       "      <td>2024-12-13 18:59:14</td>\n",
       "      <td>2024-02-02 20:21:09</td>\n",
       "      <td>Inverse Reinforcement Learning by Estimating E...</td>\n",
       "      <td>In Imitation Learning (IL), utilizing subopt...</td>\n",
       "      <td>cs.LG, cs.AI</td>\n",
       "      <td>11 pages, 4 figures, extended version of AAAI ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2412.10360v1</td>\n",
       "      <td>Orr Zohar,Xiaohan Wang,Yann Dubois,Nikhil Meht...</td>\n",
       "      <td>2024-12-13 18:53:24</td>\n",
       "      <td>2024-12-13 18:53:24</td>\n",
       "      <td>Apollo: An Exploration of Video Understanding ...</td>\n",
       "      <td>Despite the rapid integration of video perce...</td>\n",
       "      <td>cs.CV, cs.AI</td>\n",
       "      <td>https://apollo-lmms.github.io</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2412.10354v1</td>\n",
       "      <td>Jean Kossaifi,Nikola Kovachki,Zongyi Li,Davit ...</td>\n",
       "      <td>2024-12-13 18:49:37</td>\n",
       "      <td>2024-12-13 18:49:37</td>\n",
       "      <td>A Library for Learning Neural Operators</td>\n",
       "      <td>We present NeuralOperator, an open-source Py...</td>\n",
       "      <td>cs.LG, cs.AI</td>\n",
       "      <td>Not available</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       paper_id                                            authors  \\\n",
       "0  2412.10373v1  Sicheng Zuo,Wenzhao Zheng,Yuanhui Huang,Jie Zh...   \n",
       "1  2412.10371v1  Wenzhao Zheng,Junjie Wu,Yao Zheng,Sicheng Zuo,...   \n",
       "2  2402.01886v2                      Mark Beliaev,Ramtin Pedarsani   \n",
       "3  2412.10360v1  Orr Zohar,Xiaohan Wang,Yann Dubois,Nikhil Meht...   \n",
       "4  2412.10354v1  Jean Kossaifi,Nikola Kovachki,Zongyi Li,Davit ...   \n",
       "\n",
       "               updated            published  \\\n",
       "0  2024-12-13 18:59:54  2024-12-13 18:59:54   \n",
       "1  2024-12-13 18:59:30  2024-12-13 18:59:30   \n",
       "2  2024-12-13 18:59:14  2024-02-02 20:21:09   \n",
       "3  2024-12-13 18:53:24  2024-12-13 18:53:24   \n",
       "4  2024-12-13 18:49:37  2024-12-13 18:49:37   \n",
       "\n",
       "                                               title  \\\n",
       "0  GaussianWorld: Gaussian World Model for Stream...   \n",
       "1  GaussianAD: Gaussian-Centric End-to-End Autono...   \n",
       "2  Inverse Reinforcement Learning by Estimating E...   \n",
       "3  Apollo: An Exploration of Video Understanding ...   \n",
       "4            A Library for Learning Neural Operators   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    3D occupancy prediction is important for aut...   \n",
       "1    Vision-based autonomous driving shows great ...   \n",
       "2    In Imitation Learning (IL), utilizing subopt...   \n",
       "3    Despite the rapid integration of video perce...   \n",
       "4    We present NeuralOperator, an open-source Py...   \n",
       "\n",
       "                   categories  \\\n",
       "0         cs.CV, cs.AI, cs.LG   \n",
       "1  cs.CV, cs.AI, cs.LG, cs.RO   \n",
       "2                cs.LG, cs.AI   \n",
       "3                cs.CV, cs.AI   \n",
       "4                cs.LG, cs.AI   \n",
       "\n",
       "                                             comment  topic_count  \\\n",
       "0  Code is available at: https://github.com/zuosc...            3   \n",
       "1  Code is available at: https://github.com/wzzhe...            4   \n",
       "2  11 pages, 4 figures, extended version of AAAI ...            2   \n",
       "3                      https://apollo-lmms.github.io            2   \n",
       "4                                      Not available            2   \n",
       "\n",
       "   published_year  \n",
       "0            2024  \n",
       "1            2024  \n",
       "2            2024  \n",
       "3            2024  \n",
       "4            2024  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bổ sung các thư viện cho quá trình huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "# from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chuyển đổi nhãn\n",
    "- Ghép tiêu đề và tóm tắt của bài báo\n",
    "- Chuyển nhãn thành dạng nhị phân"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các tham số\n",
    "MODEL_NAME = 'microsoft/deberta-v3-small'  # Mô hình DeBERTa\n",
    "NUM_CLASSES = 20  # Số lớp phân loại (cần thay đổi theo số lượng danh mục bài báo của bạn)\n",
    "\n",
    "# Tiền xử lý: Ghép tiêu đề và tóm tắt lại\n",
    "raw_df['text'] = raw_df['title'] + \" \" + raw_df['abstract']\n",
    "\n",
    "# Chuyển nhãn thành các giá trị nhị phân (ví dụ: cho nhiều nhãn)\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(raw_df['categories'].apply(lambda x: x.split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tiền xử lý văn bản\n",
    "- Chuyển văn bản về chữ thường.\n",
    "- Loại bỏ ký tự đặc biệt và giữ lại chữ cái và khoảng trắng.\n",
    "- Loại bỏ stopwords (các từ không mang nhiều ý nghĩa như 'the', 'is',...).\n",
    "- Thực hiện lemmatization (đưa từ về dạng cơ bản, ví dụ: \"running\" -> \"run\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tải các tài nguyên cần thiết từ NLTK\n",
    "nltk.download('punkt')  # Để sử dụng word_tokenize\n",
    "nltk.download('stopwords')  # Để sử dụng stopwords\n",
    "nltk.download('wordnet')  # Để sử dụng lemmatizer\n",
    "\n",
    "\n",
    "# Khởi tạo lemmatizer và stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tiền xử lý dữ liệu\n",
    "raw_df['text'] = raw_df['text'].str.lower()  # Chuyển về chữ thường\n",
    "raw_df['text'] = raw_df['text'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))  # Loại bỏ ký tự đặc biệt\n",
    "raw_df['text'] = raw_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))  # Loại bỏ stopwords\n",
    "raw_df['text'] = raw_df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))  # Lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Chia dữ liệu thành tập huấn luyện và tập kiểm tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(raw_df['text'], labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tokenize văn bản:\n",
    "- Tải tokenizer của mô hình DeBERTa.\n",
    "- Tokenize dữ liệu huấn luyện và kiểm tra:\n",
    "    - Thêm padding để đảm bảo các chuỗi có cùng độ dài.\n",
    "    - Cắt bớt chuỗi dài hơn giới hạn (max_length = 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải tokenizer của DeBERTa\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Tokenize văn bản\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=200)\n",
    "\n",
    "train_encodings = tokenizer(list(train_texts), padding=True, truncation=True, max_length=200)\n",
    "val_encodings = tokenizer(list(val_texts), padding=True, truncation=True, max_length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Chuẩn bị DataLoader:\n",
    "- Chuyển dữ liệu tokenized và nhãn thành TensorDataset để sử dụng với PyTorch.\n",
    "- Tạo DataLoader cho tập huấn luyện và kiểm tra:\n",
    "    - train_dataloader: Dùng để huấn luyện, với shuffle=True để xáo trộn dữ liệu.\n",
    "    - val_dataloader: Dùng để kiểm tra mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi dữ liệu thành Tensor\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_encodings['input_ids']), torch.tensor(train_labels))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(val_encodings['input_ids']), torch.tensor(val_labels))\n",
    "\n",
    "# Tạo DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải mô hình DeBERTa với số lượng nhãn được chỉ định (num_labels = NUM_CLASSES).\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_CLASSES)\n",
    "\n",
    "# Cấu hình optimizer AdamW để tối ưu hóa với AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Huấn luyện và đánh giá mô hình:\n",
    "- Thiết lập thiết bị (GPU nếu có, nếu không thì dùng CPU).\n",
    "- Huấn luyện mô hình qua nhiều epoch:\n",
    "    - Chạy mô hình trên tập huấn luyện (train_dataloader).\n",
    "    - Tính toán loss với BCEWithLogitsLoss cho bài toán phân loại đa nhãn.\n",
    "    - Thực hiện backward pass và cập nhật trọng số.\n",
    "- Đánh giá trên tập kiểm tra (val_dataloader):\n",
    "    - Sử dụng sigmoid để chuyển logits thành xác suất và so sánh với ngưỡng 0.\n",
    "    - Tính toán accuracy dựa trên các dự đoán và nhãn thực tế."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "# Huấn luyện mô hình\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Huấn luyện (Epochs)\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loop = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{epochs}')\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        # Forward pass (Chạy mô hình)\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        logits = outputs.logits  # Lấy logits đầu ra từ mô hình\n",
    "\n",
    "        # Sử dụng BCEWithLogitsLoss cho multi-label classification\n",
    "        loss_fn = BCEWithLogitsLoss()\n",
    "        loss = loss_fn(logits, labels.float())  # Chuyển labels sang float\n",
    "\n",
    "        # Backward pass (Cập nhật trọng số mô hình)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Đánh giá trên tập kiểm tra (validation)\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            # Forward pass (Chạy mô hình)\n",
    "            outputs = model(input_ids)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Tính dự đoán (điểm số > 0.5 cho mỗi lớp)\n",
    "            preds = torch.sigmoid(logits) > 0.5  # Các giá trị đầu ra >= 0.5 được coi là nhãn đúng\n",
    "\n",
    "            # Cộng dồn các kết quả\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_predictions += labels.numel()  # Tổng số nhãn\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())  # Chuyển labels sang numpy để tính accuracy\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    # Tính accuracy theo toàn bộ dataset\n",
    "    accuracy = accuracy_score(np.concatenate(all_labels), np.concatenate(all_preds))\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Lưu mô hình đã huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./deberta_model')\n",
    "tokenizer.save_pretrained('./deberta_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/deberta_model\n",
    "!zip -r deberta_model.zip /content/deberta_model\n",
    "from google.colab import files\n",
    "files.download('deberta_model.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
